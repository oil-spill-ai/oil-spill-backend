# Документация по backend микросервису Oil Spill AI

## Оглавление
- [Общее описание](#общее-описание)
- [Архитектура](#архитектура)
- [Запуск backend-сервера](#запуск-backend-сервера)
- [Запуск Celery worker и Redis](#запуск-celery-worker-и-redis)
- [API эндпоинты](#api-эндпоинты)
- [Взаимодействие с ML микросервисом](#взаимодействие-с-ml-микросервисом)
- [Структура проекта](#структура-проекта)
- [Зависимости](#зависимости)

---

## Общее описание

Backend реализован на FastAPI и предназначен для приёма zip-архивов с изображениями, передачи их на обработку ML микросервису (выделение разливов нефти), асинхронной обработки через Celery и возврата пользователю zip-архива с результатами.

## Архитектура

- **FastAPI** — основной HTTP сервер, реализует REST API для загрузки архивов, скачивания результатов и проверки статуса задач.
- **Celery** — асинхронная очередь задач, используется для обработки изображений в фоне.
- **Redis** — брокер и backend для Celery.
- **ML микросервис** — отдельный HTTP сервер (см. директорию `ml`), к которому backend обращается по HTTP для сегментации изображений.

## Запуск backend-сервера

1. Установите зависимости:

```bash
pip install -r requirements.txt
```

2. Запустите FastAPI сервер (например, через uvicorn):

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

## Запуск Celery worker и Redis

1. Запустите Redis сервер (если не запущен):

```bash
docker run --name redis-container -p 6379:6379 -d redis
```

2. Запустите Celery worker:

```bash
celery -A app worker --loglevel=info
```

- Переменные окружения `CELERY_BROKER_URL` и `CELERY_RESULT_BACKEND` по умолчанию указывают на `redis://localhost:6379/0`.

## API эндпоинты

### POST `/api/upload`
Загрузка zip-архива с изображениями. Возвращает job_id для отслеживания статуса.

### GET `/api/status/{job_id}`
Проверка статуса задачи по её идентификатору.

### GET `/api/download/{user_hash}`
Скачивание zip-архива с результатами обработки.

## Взаимодействие с ML микросервисом

- Для обработки каждого изображения вызывается HTTP POST на эндпоинт ML сервиса (`ML_SERVICE_URL`, по умолчанию `http://localhost:8002/segment`).
- Ответ ML сервиса должен содержать изображение с сегментацией. Backend сохраняет результат и формирует итоговый архив.

## Структура проекта

```
backend/
├── app/
│   ├── main.py           # FastAPI-приложение, основные эндпоинты
│   ├── celery_worker.py  # Инициализация Celery
│   ├── tasks.py          # Celery задачи для обработки архивов
│   ├── utils.py          # Вспомогательные функции, взаимодействие с ML сервисом
├── requirements.txt      # Зависимости Python
├── Dockerfile            # (если используется)
├── .env                  # Переменные окружения (опционально)
└── README.md             # Документация (этот файл)
```

## Зависимости

Основные зависимости (см. `requirements.txt`):
- fastapi
- uvicorn
- celery[redis]
- redis
- requests
- aiofiles
- python-multipart
- python-dotenv
- httpx

---

### Примечания
- Для работы требуется запущенный ML микросервис (см. директорию `ml`).
- Все временные и итоговые файлы хранятся в директории `results/`.
- Для настройки CORS и переменных окружения используйте `.env`.

Если возникли вопросы по запуску или интеграции — обратитесь к разработчику или смотрите исходный код файлов в директории `app/`.
